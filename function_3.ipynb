{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "559a1ce0-4b36-40a3-bf2d-20b77f4390d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Hp\\anaconda3\\envs\\newenv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "263a17b7-6cc0-42ec-804a-c0eb649d46c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyImageClassifier:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.train_accuracy = None\n",
    "        self.test_accuracy = None\n",
    "\n",
    "    def build_model(self):\n",
    "        # Build your model here (replace with your architecture)\n",
    "        model = tf.keras.Sequential([\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(2, activation='softmax')  # Assuming 2 classes (male and female)\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        self.model = model\n",
    "\n",
    "    def load_data(self, batch_size=32):\n",
    "        # Load your data here and return train_dataset and test_dataset\n",
    "        # Replace the following lines with your data loading logic\n",
    "\n",
    "        data_directory = r'C:\\Users\\Hp\\Downloads\\VW_AI\\dataset'\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "        train_dataset = train_datagen.flow_from_directory(\n",
    "            data_directory,\n",
    "            target_size=(224, 224),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='sparse',\n",
    "            subset='training'\n",
    "        )\n",
    "\n",
    "        test_dataset = train_datagen.flow_from_directory(\n",
    "            data_directory,\n",
    "            target_size=(224, 224),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='sparse',\n",
    "            subset='validation'\n",
    "        )\n",
    "\n",
    "        return train_dataset, test_dataset\n",
    "\n",
    "    def train_model(self, train_generator, test_generator, epochs=10):\n",
    "        # Implement a learning rate schedule\n",
    "        def lr_schedule(epoch):\n",
    "            if epoch < 10:\n",
    "                return 0.001\n",
    "            elif epoch < 20:\n",
    "                return 0.0001\n",
    "            else:\n",
    "                return 0.00001\n",
    "\n",
    "        lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "        history = self.model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=max(1, train_generator.samples // train_generator.batch_size),\n",
    "            epochs=epochs,\n",
    "            validation_data=test_generator,\n",
    "            validation_steps=max(1, test_generator.samples // test_generator.batch_size),\n",
    "            callbacks=[lr_callback]\n",
    "        )\n",
    "        return history\n",
    "\n",
    "    def evaluate_model(self, test_generator):\n",
    "        # Add your evaluation logic here\n",
    "        evaluation = self.model.evaluate(test_generator)\n",
    "        print(\"Evaluation Results:\", evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f0d804b-e2cd-43a1-ab57-85a0dc1f9e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 images belonging to 2 classes.\n",
      "Found 2 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6948 - accuracy: 0.5714 - val_loss: 84.0172 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 67.5981 - accuracy: 0.5000 - val_loss: 7.9273 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 1s 997ms/step - loss: 5.4514 - accuracy: 0.5000 - val_loss: 0.8462 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1774 - accuracy: 0.9286 - val_loss: 8.9153 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.9891 - accuracy: 0.5000 - val_loss: 14.7313 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8.6057 - accuracy: 0.5000 - val_loss: 6.8629 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 1s 990ms/step - loss: 2.3604 - accuracy: 0.6429 - val_loss: 14.3301 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 6.6716 - accuracy: 0.5000 - val_loss: 13.0288 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.1450 - accuracy: 0.5714 - val_loss: 0.7242 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0741 - accuracy: 0.9286 - val_loss: 10.3088 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7772 - accuracy: 0.6429 - val_loss: 10.2294 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.6947 - accuracy: 0.6429 - val_loss: 9.3287 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.1763 - accuracy: 0.7143 - val_loss: 7.8478 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.5434 - accuracy: 0.8571 - val_loss: 6.0309 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9609 - accuracy: 0.8571 - val_loss: 4.0244 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5674 - accuracy: 0.9286 - val_loss: 1.9842 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2606 - accuracy: 0.9286 - val_loss: 0.4074 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 1.2690 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1732 - accuracy: 0.9286 - val_loss: 2.7295 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4607 - accuracy: 0.8571 - val_loss: 3.7068 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 3.7068 - accuracy: 0.5000\n",
      "Evaluation Results: [3.706777334213257, 0.5]\n"
     ]
    }
   ],
   "source": [
    "classifier = MyImageClassifier()\n",
    "classifier.build_model()\n",
    "train_dataset, test_dataset = classifier.load_data(batch_size=32)\n",
    "history = classifier.train_model(train_dataset, test_dataset, epochs=20)  # Try training for more epochs\n",
    "classifier.evaluate_model(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f8da0d-e4c4-4587-a003-42802ba097e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
